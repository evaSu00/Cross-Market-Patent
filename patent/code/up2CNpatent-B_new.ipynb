{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/senior/.conda/envs/python38/lib/python3.8/site-packages/requests/__init__.py:78: RequestsDependencyWarning: urllib3 (1.26.8) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({0}) or chardet ({1}) doesn't match a supported \"\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import urllib3\n",
    "from pymongo import MongoClient\n",
    "import re\n",
    "from multiprocessing import Pool\n",
    "import traceback\n",
    "from selenium import webdriver\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_error(e):\n",
    "    #處理 child process 的錯誤，不然 code 寫錯時，不會回報任何錯誤\n",
    "    traceback.print_exception(type(e), e, e.__traceback__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patent_soup(patent_num):\n",
    "    urllib3.disable_warnings() #禁用各種警告\n",
    "    response = requests.get('https://patents.google.com/patent/' + str(patent_num),verify = False)\n",
    "    response.encoding='utf-8'\n",
    "    if response.status_code != 200:\n",
    "        pass\n",
    "    else:\n",
    "        soup =  BeautifulSoup(response.text, 'html.parser') \n",
    "        try:\n",
    "            appDate = soup.find('time', itemprop=\"filingDate\").string.replace('-', '')\n",
    "            \n",
    "            # Classifications\n",
    "            try:\n",
    "                classifications = soup.find_all('span', itemprop=\"Code\")\n",
    "                classification =[]\n",
    "                for i in range(0,len(classifications)):\n",
    "                    try:\n",
    "                        if len(classifications[i].string)>len(classifications[i+1].string):\n",
    "                            classification.append(classifications[i].string)\n",
    "                        elif i == len(classifications)-2:\n",
    "                            classification.append(classifications[i+1].string) \n",
    "                    except:\n",
    "                        pass\n",
    "                if classification[0] == '':\n",
    "                    classification = None\n",
    "            except:\n",
    "                classification = None\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "    return appDate, classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 取得html\n",
    "def soup(url):\n",
    "    urllib3.disable_warnings() #禁用各種警告\n",
    "    response = requests.get(url,verify = False)\n",
    "    response.encoding='utf-8'\n",
    "    if response.status_code != 200:\n",
    "        pass\n",
    "    else:\n",
    "        soup =  BeautifulSoup(response.text, 'html.parser') \n",
    "        try:\n",
    "            patent_num = soup.find('dd',itemprop='publicationNumber').string\n",
    "            appDate = soup.find('time', itemprop=\"filingDate\").string.replace('-', '')\n",
    "            pubDate = soup.find('time', itemprop=\"publicationDate\").string.replace('-', '')\n",
    "            abstract = soup.find('div',{\"class\":\"abstract\"}).string\n",
    "            title = re.sub('\\s','',soup.find('span',itemprop=\"title\").string)\n",
    "            \n",
    "            #current assignee\n",
    "            try:\n",
    "                current = soup.find_all('dd' ,itemprop=\"assigneeCurrent\")\n",
    "                current_assignee = []\n",
    "                for i in current:\n",
    "                    i = re.sub('\\n','',i.string)\n",
    "                    i = ' '.join(i.split())\n",
    "                    current_assignee.append(i)\n",
    "            except:\n",
    "                current_assignee = None\n",
    "            \n",
    "            #original assignee\n",
    "            try:\n",
    "                original = soup.find_all('dd' ,itemprop=\"assigneeOriginal\")\n",
    "                original_assignee = []\n",
    "                for i in original:\n",
    "                    original_assignee.append(i.string)\n",
    "            except:\n",
    "                original_assignee = None\n",
    "            \n",
    "            #graDate\n",
    "            Date = soup.find_all('tr',itemprop=\"legalEvents\")\n",
    "            graDate = 'N/A'\n",
    "            for i in Date:\n",
    "#                 if re.search('.*Grant.*',i.text) != None or re.search('.*grant.*',i.text) != None:\n",
    "#                     graDate =re.sub('\\s','',i.text)[:10].replace('-', '')\n",
    "#                 else:\n",
    "#                     graDate = graDate\n",
    "                if i.find('td', itemprop='title').text == 'Information on status: patent grant':\n",
    "                    graDate =re.sub('\\s','',i.text)[:10].replace('-', '')\n",
    "            \n",
    "            # inventorName\n",
    "            try:\n",
    "                inventorNames = soup.find_all('dd',itemprop=\"inventor\")\n",
    "                inventorName = []\n",
    "                for i in inventorNames:\n",
    "                    inventorName.append(i.string)\n",
    "            except:\n",
    "                inventorName = None\n",
    "\n",
    "            # description\n",
    "#             try:\n",
    "#                 description = soup.find_all('p')\n",
    "#                 description_list = []\n",
    "#                 for i in description:\n",
    "#                     description_list.append(re.sub('\\s','',i.text))\n",
    "#                 description = (\"\".join(description_list)) \n",
    "#             except:\n",
    "#                 description = None\n",
    "            if graDate != 'N/A':\n",
    "                try:\n",
    "                    descriptions = soup.find_all('div', class_=\"description-paragraph\")\n",
    "                    description = ''\n",
    "                    for i in descriptions:\n",
    "                        description += i.text\n",
    "                except:\n",
    "                    description = None\n",
    "            else:\n",
    "                try:\n",
    "                    descriptions = soup.find_all('div', class_=\"description-line\")\n",
    "                    description = ''\n",
    "                    for i in descriptions:\n",
    "                        description += i.text\n",
    "                except:\n",
    "                    description = None\n",
    "                                \n",
    "            # detailed_description\n",
    "#             try:\n",
    "#                 detailed_description_list = soup.find_all('p')\n",
    "#                 detailed_description_start = 0\n",
    "#                 detailed_description = ''\n",
    "                            \n",
    "#                 for num,i in enumerate(detailed_description_list):\n",
    "#                     if re.sub('\\s','',i.text) == '具体实施方式':\n",
    "#                         detailed_description_start = num\n",
    "#                 if detailed_description_start > 0:\n",
    "#                     for i in range(detailed_description_start,len(detailed_description_list)):\n",
    "#                         detailed_description += re.sub('\\s','',detailed_description_list[i].text)\n",
    "#                     detailed_description = \"\".join(detailed_description)\n",
    "#                 else:\n",
    "#                     detailed_description = None\n",
    "#             except:\n",
    "#                 detailed_description = None\n",
    "                \n",
    "            # claim\n",
    "            try:\n",
    "                claims = soup.find_all('div',{'class':'claim-text'})\n",
    "                claim = []\n",
    "                j = 0\n",
    "                for i in claims:\n",
    "                    if re.sub('\\s','',i.text) != '':\n",
    "                        claim.append(re.sub('\\s','',i.text))\n",
    "            #分類\n",
    "                for i in range(1,len(claim)-1):\n",
    "                    try:\n",
    "                        int(claim[i][0])\n",
    "                        j = i\n",
    "                    except:\n",
    "                        a = str(claim[j])+str(claim[i])\n",
    "                        claim[j] = a\n",
    "                        claim[i] = '' \n",
    "                for i in claim:\n",
    "                    if '' in claim:\n",
    "                        claim.remove('')\n",
    "            except:\n",
    "                claim = None\n",
    "\n",
    "            # patentCited    \n",
    "            try:\n",
    "                patentCiteds = soup.find_all('tr', itemprop=\"backwardReferences\")\n",
    "                patentCited_list = []\n",
    "                patentCited_assignee_list = []\n",
    "                patentCited = []\n",
    "                for i in patentCiteds:\n",
    "                    patentCited_assignee_list.append(i.find('span', itemprop=\"assigneeOriginal\").text)\n",
    "                    e = re.sub('\\s','',i.text).find(\"(\")\n",
    "                    patentCited_list.append(re.sub('\\s','',i.text)[:e])\n",
    "                if len(patentCited_list) != 0 :\n",
    "                    for j in patentCited_list:\n",
    "                        pclist = {'pto':None,'patentNumber':None,'kindcode':None, 'appDate':None, 'assignee':None, 'classification':None}\n",
    "                        pclist['pto'] = j[:2]\n",
    "                        try:\n",
    "                            int(j[-2])\n",
    "                            try:\n",
    "                                int(j[-1])\n",
    "                                pclist['patentNumber'] = j[2:]\n",
    "                                pclist['kindcode'] = None\n",
    "                            except:\n",
    "                                pclist['patentNumber'] = j[2:-2]\n",
    "                                pclist['kindcode'] = j[-1]\n",
    "                        except:\n",
    "                            pclist['patentNumber'] = j[2:-2]\n",
    "                            pclist['kindcode'] = j[-2:]\n",
    "                        try:                   \n",
    "                            cited_appDate, cited_classification = patent_soup(j)\n",
    "                            pclist['appDate'] = cited_appDate\n",
    "                            pclist['classification'] = cited_classification\n",
    "                        except:\n",
    "                            pclist['appDate'] = None\n",
    "                            pclist['classification'] = None\n",
    "                        patentCited.append(pclist)\n",
    "                    for i in range(len(patentCited)):\n",
    "                        try:\n",
    "                            patentCited[i]['assignee'] = patentCited_assignee_list[i]\n",
    "                        except:\n",
    "                            patentCited[i]['assignee'] = None\n",
    "                else:\n",
    "                    patentCited = None\n",
    "                    \n",
    "            except:\n",
    "                patentCited = None\n",
    "                \n",
    "            # Family To Family Citing      \n",
    "            try:\n",
    "                family_to_family_citings = soup.find_all('tr', itemprop=\"backwardReferencesFamily\")\n",
    "                family_to_family_citing_list = []\n",
    "                family_to_family_citing_assignee_list = []\n",
    "                family_to_family_citing = []\n",
    "                for i in family_to_family_citings:\n",
    "                    family_to_family_citing_assignee_list.append(i.find('span', itemprop=\"assigneeOriginal\").text)\n",
    "                    e = re.sub('\\s','',i.text).find(\"(\")\n",
    "                    family_to_family_citing_list.append(re.sub('\\s','',i.text)[:e])\n",
    "                    \n",
    "                if len(family_to_family_citing_list) != 0 :\n",
    "                    for j in family_to_family_citing_list:\n",
    "                        clist = {'pto':None,'patentNumber':None,'kindcode':None, 'appDate':None, 'assignee':None, 'classification':None}\n",
    "                        clist['pto'] = j[:2]\n",
    "                        try:\n",
    "                            int(j[-2])\n",
    "                            try:\n",
    "                                int(j[-1])\n",
    "                                clist['patentNumber'] = j[2:]\n",
    "                                clist['kindcode'] = None\n",
    "                            except:\n",
    "                                clist['patentNumber'] = j[2:-2]\n",
    "                                clist['kindcode'] = j[-1]\n",
    "                        except:\n",
    "                            clist['patentNumber'] = j[2:-2]\n",
    "                            clist['kindcode'] = j[-2:]\n",
    "                        try:                   \n",
    "                            citing_appDate, citing_classification = patent_soup(j)\n",
    "                            clist['appDate'] = citing_appDate\n",
    "                            clist['classification'] = citing_classification\n",
    "                        except:\n",
    "                            clist['appDate'] = None\n",
    "                            clist['classification'] = None\n",
    "                        family_to_family_citing.append(clist) \n",
    "                    for i in range(len(family_to_family_citing)):\n",
    "                        try:\n",
    "                            family_to_family_citing[i]['assignee'] = family_to_family_citing_assignee_list[i]\n",
    "                        except:\n",
    "                            family_to_family_citing[i]['assignee'] = None\n",
    "                else:\n",
    "                    family_to_family_citing = None\n",
    "            except:\n",
    "                family_to_family_citing = None\n",
    "                \n",
    "            # ＣountryStatus\n",
    "            try:\n",
    "                status =  soup.find_all('tr', itemprop=\"countryStatus\")\n",
    "                countrystatus = []\n",
    "                for i in status:\n",
    "                    countrycode = i.find('span', itemprop=\"countryCode\")\n",
    "                    try:\n",
    "                        countrystatus.index(countrycode.string)\n",
    "                    except:\n",
    "                        countrystatus.append(countrycode.string)\n",
    "            except:\n",
    "                countrystatus = None\n",
    "            \n",
    "            # Cited       \n",
    "            try:\n",
    "                citeds_1 = soup.find_all('tr' ,itemprop=\"forwardReferencesOrig\" )\n",
    "                #citeds_2 = soup.find_all('tr', itemprop=\"forwardReferencesFamily\")\n",
    "                cited_list = []\n",
    "                cited_assignee_list = []\n",
    "                cited = []\n",
    "                for i in citeds_1:\n",
    "                    cited_assignee_list.append(i.find('span', itemprop=\"assigneeOriginal\").text)\n",
    "                    e = re.sub('\\s','',i.text).find(\"(\")\n",
    "                    cited_list.append(re.sub('\\s','',i.text)[:e])\n",
    "#                 for i in citeds_2:\n",
    "#                     e = re.sub('\\s','',i.text).find(\"(\")\n",
    "#                     cited_list.append(re.sub('\\s','',i.text)[:e])\n",
    "                    \n",
    "                if len(cited_list) != 0 :\n",
    "                    for j in cited_list:\n",
    "                        clist = {'pto':None,'patentNumber':None,'kindcode':None, 'appDate':None, 'assignee':None, 'classification':None}\n",
    "                        clist['pto'] = j[:2]\n",
    "                        try:\n",
    "                            int(j[-2])\n",
    "                            try:\n",
    "                                int(j[-1])\n",
    "                                clist['patentNumber'] = j[2:]\n",
    "                                clist['kindcode'] = None\n",
    "                            except:\n",
    "                                clist['patentNumber'] = j[2:-2]\n",
    "                                clist['kindcode'] = j[-1]\n",
    "                        except:\n",
    "                            clist['patentNumber'] = j[2:-2]\n",
    "                            clist['kindcode'] = j[-2:]\n",
    "                        try:                   \n",
    "                            cited_appDate, cited_classification = patent_soup(j)\n",
    "                            clist['appDate'] = cited_appDate\n",
    "                            clist['classification'] = cited_classification\n",
    "                        except:\n",
    "                            clist['appDate'] = None\n",
    "                            clist['classification'] = None\n",
    "                        cited.append(clist)\n",
    "                    for i in range(len(cited)):\n",
    "                        try:\n",
    "                            cited[i]['assignee'] = cited_assignee_list[i]\n",
    "                        except:\n",
    "                            cited[i]['assignee'] = None\n",
    "                \n",
    "                else:\n",
    "                    cited = None\n",
    "            except:\n",
    "                cited = None\n",
    "                \n",
    "            # Family To Family Cited      \n",
    "            try:\n",
    "                family_to_family_citeds = soup.find_all('tr', itemprop=\"forwardReferencesFamily\")\n",
    "                family_to_family_cited_list = []\n",
    "                family_to_family_cited_assignee_list = []\n",
    "                family_to_family_cited = []\n",
    "                for i in family_to_family_citeds:\n",
    "                    family_to_family_cited_assignee_list.append(i.find('span', itemprop=\"assigneeOriginal\").text)\n",
    "                    e = re.sub('\\s','',i.text).find(\"(\")\n",
    "                    family_to_family_cited_list.append(re.sub('\\s','',i.text)[:e])\n",
    "                    \n",
    "                if len(family_to_family_cited_list) != 0 :\n",
    "                    for j in family_to_family_cited_list:\n",
    "                        clist = {'pto':None,'patentNumber':None,'kindcode':None, 'appDate':None, 'assignee':None, 'classification':None}\n",
    "                        clist['pto'] = j[:2]\n",
    "                        try:\n",
    "                            int(j[-2])\n",
    "                            try:\n",
    "                                int(j[-1])\n",
    "                                clist['patentNumber'] = j[2:]\n",
    "                                clist['kindcode'] = None\n",
    "                            except:\n",
    "                                clist['patentNumber'] = j[2:-2]\n",
    "                                clist['kindcode'] = j[-1]\n",
    "                        except:\n",
    "                            clist['patentNumber'] = j[2:-2]\n",
    "                            clist['kindcode'] = j[-2:]\n",
    "                        try:                   \n",
    "                            cited_appDate, cited_classification = patent_soup(j)\n",
    "                            clist['appDate'] = cited_appDate\n",
    "                            clist['classification'] = cited_classification\n",
    "                        except:\n",
    "                            clist['appDate'] = None\n",
    "                            clist['classification'] = None\n",
    "                        family_to_family_cited.append(clist) \n",
    "                    for i in range(len(family_to_family_cited)):\n",
    "                        try:\n",
    "                            family_to_family_cited[i]['assignee'] = family_to_family_cited_assignee_list[i]\n",
    "                        except:\n",
    "                            family_to_family_cited[i]['assignee'] = None\n",
    "                else:\n",
    "                    family_to_family_cited = None\n",
    "            except:\n",
    "                family_to_family_cited = None\n",
    "\n",
    "            # Classifications\n",
    "            try:\n",
    "                classifications = soup.find_all('span', itemprop=\"Code\")\n",
    "                classification =[]\n",
    "                for i in range(0,len(classifications)):\n",
    "                    try:\n",
    "                        if len(classifications[i].string)>len(classifications[i+1].string):\n",
    "                            classification.append(classifications[i].string)\n",
    "                        elif i == len(classifications)-2:\n",
    "                            classification.append(classifications[i+1].string) \n",
    "                    except:\n",
    "                        pass\n",
    "                if classification[0] == '':\n",
    "                    classification = None\n",
    "            except:\n",
    "                classification = None\n",
    "                \n",
    "            # Similar Documents\n",
    "            try:\n",
    "                similar_docs = soup.find_all('tr', itemprop=\"similarDocuments\")\n",
    "                similarDocuments = []\n",
    "                similar_doc =[]\n",
    "                doc_title = []\n",
    "                doc_publication = []\n",
    "                doc_time = []\n",
    "\n",
    "                for doc in similar_docs:\n",
    "                    publication = doc.find_all('span')\n",
    "                    time = doc.find_all('time')\n",
    "                    titles = doc.find_all('td', itemprop=\"title\")\n",
    "\n",
    "                    for j1 in publication:\n",
    "                        if len(j1.text.strip())!=2:\n",
    "                            doc_publication.append(j1.text.strip())\n",
    "                    for j2 in time:\n",
    "                        doc_time.append(j2.text.strip())\n",
    "                    for j3 in titles:\n",
    "                        doc_title.append(j3.text.strip())\n",
    "                similarDocuments = []\n",
    "                for i in range(len(doc_publication)):\n",
    "                    doc={\n",
    "                        'publication' : doc_publication[i],\n",
    "                        'time' : doc_time[i],\n",
    "                        'title' : doc_title[i]\n",
    "                        }\n",
    "                    similarDocuments.append(doc)\n",
    "            except:\n",
    "                similarDocuments = None\n",
    "                \n",
    "\n",
    "            data = {\n",
    "            'patentNumber':patent_num,\n",
    "            'inventorName':inventorName,\n",
    "            'current_assignee':current_assignee,\n",
    "            'original_assignee':original_assignee,\n",
    "            'appDate':appDate,\n",
    "            'pubDate':pubDate ,\n",
    "            'graDate':graDate,\n",
    "            'classification':classification,\n",
    "            'brief':abstract,\n",
    "            'title':title,\n",
    "            'description':description,\n",
    "#             'detailed_description':detailed_description,\n",
    "            'claim':claim,\n",
    "            'countrystatus':countrystatus,\n",
    "            'patentCitation':patentCited,\n",
    "            'family_to_family_citing':family_to_family_citing,\n",
    "            'cited':cited,\n",
    "            'family_to_family_cited':family_to_family_cited,\n",
    "            'similarDocuments':similarDocuments\n",
    "            }\n",
    "            return data\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "def search_google_patent(keyword='', assignee=[], s_date='', e_date=''):\n",
    "    assignees = ''\n",
    "    for i in assignee:\n",
    "        for j in i.split():\n",
    "            assignees += str(j)\n",
    "            assignees += '+'\n",
    "        assignees += ','\n",
    "    url = 'https://patents.google.com/?q=' + keyword + '&assignee=' + assignees + '&country=US&before=filing:' + e_date + '&after=filing:' + s_date + '&language=ENGLISH&type=PATENT'\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--headless')\n",
    "    options.add_argument('--disable-infobars')\n",
    "    options.add_argument('--no-sandbox')\n",
    "\n",
    "    driver = webdriver.Chrome(chrome_options=options, executable_path='./chromedriver')\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    html = driver.page_source\n",
    "    driver.close()\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    \n",
    "    csv_url = 'https://patents.google.com/' + soup.find('a', class_='style-scope search-results')['href']\n",
    "    urllib.request.urlretrieve(csv_url, \"US_patent.csv\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sshtunnel'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-53fd1c4177e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpymongo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMongoClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msshtunnel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSSHTunnelForwarder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpymongo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'sshtunnel'"
     ]
    }
   ],
   "source": [
    "from pymongo import MongoClient\n",
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pymongo\n",
    "from tqdm import tqdm\n",
    "\n",
    "def insert_data(year, data):\n",
    "    MONGO_HOST = \"140.127.32.24\"\n",
    "    MONGO_USER = \"chiayu\"\n",
    "    MONGO_PASS = \"npustmiscylab7097\"\n",
    "    MONGO_DB = \"2022_Patent_Innovation\"\n",
    "    MONGO_COLLECTION = \"20\" + year + \"_Patent_Innovation\"\n",
    "    \n",
    "    server = SSHTunnelForwarder(\n",
    "        MONGO_HOST,\n",
    "        ssh_username=MONGO_USER,\n",
    "        ssh_password=MONGO_PASS,\n",
    "        remote_bind_address=('140.127.32.23', 27017)\n",
    "    )\n",
    "    \n",
    "    server.start()\n",
    "\n",
    "    conn = pymongo.MongoClient('127.0.0.1',server.local_bind_port)\n",
    "    conn.admin.authenticate('dnlab', 'dnlab8787')\n",
    "    conn_db = conn[MONGO_DB]\n",
    "    conn_db_collection = conn_db[MONGO_COLLECTION]\n",
    "    \n",
    "    conn_db_collection.insert_one(data)\n",
    "\n",
    "    server.stop()\n",
    "    \n",
    "def SearchYear(year):\n",
    "    MONGO_HOST = \"140.127.32.24\"\n",
    "    MONGO_USER = \"chiayu\"\n",
    "    MONGO_PASS = \"npustmiscylab7097\"\n",
    "    MONGO_DB = \"Google_Patent_Research\"\n",
    "    MONGO_COLLECTION = \"application_20\" + year\n",
    "    \n",
    "    server = SSHTunnelForwarder(\n",
    "        MONGO_HOST,\n",
    "        ssh_username=MONGO_USER,\n",
    "        ssh_password=MONGO_PASS,\n",
    "        remote_bind_address=('140.127.32.23', 27017)\n",
    "    )\n",
    "    \n",
    "    server.start()\n",
    "\n",
    "    conn = pymongo.MongoClient('127.0.0.1',server.local_bind_port)\n",
    "    conn.admin.authenticate('dnlab', 'dnlab8787')\n",
    "    conn_db = conn[MONGO_DB]\n",
    "    conn_db_collection = conn_db[MONGO_COLLECTION]\n",
    "    \n",
    "    #建立索引\n",
    "    #conn_db_collection.create_index(\"assignees.orgname\", name='orgname', background=True)\n",
    "    #刪除索引\n",
    "    #data = conn_db_collection.find_one({\"assignees.orgname\":'Apple Inc'})\n",
    "    #data = conn_db_collection.find({\"assignees.orgname\":'Apple Inc'}).explain()[\"executionStats\"]\n",
    "    data = list(conn_db_collection.find({}, {'_id':0, 'url':1}))\n",
    "    #information = conn_db_collection.index_information()\n",
    "    #information = conn_db_collection.index_information()\n",
    "\n",
    "    server.stop()\n",
    "    \n",
    "    return data\n",
    "\n",
    "def SearchPatentNumber(year, num):\n",
    "    MONGO_HOST = \"140.127.32.24\"\n",
    "    MONGO_USER = \"chiayu\"\n",
    "    MONGO_PASS = \"npustmiscylab7097\"\n",
    "    MONGO_DB = \"2022_Patent_Innovation\"\n",
    "    MONGO_COLLECTION = \"20\" + year + \"_Patent_Innovation\"\n",
    "    \n",
    "    server = SSHTunnelForwarder(\n",
    "        MONGO_HOST,\n",
    "        ssh_username=MONGO_USER,\n",
    "        ssh_password=MONGO_PASS,\n",
    "        remote_bind_address=('140.127.32.23', 27017)\n",
    "    )\n",
    "    \n",
    "    server.start()\n",
    "\n",
    "    conn = pymongo.MongoClient('127.0.0.1',server.local_bind_port)\n",
    "    conn.admin.authenticate('dnlab', 'dnlab8787')\n",
    "    conn_db = conn[MONGO_DB]\n",
    "    conn_db_collection = conn_db[MONGO_COLLECTION]\n",
    "    \n",
    "    conn_db_collection.create_index(\"patentNumber\", background=True)\n",
    "    data = conn_db_collection.find_one({\"patentNumber\":num},{'_id':0, 'patentNumber':1})\n",
    "\n",
    "    server.stop()\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://patents.google.com/?q=&assignee=Apple+Inc.+,Google+LLC.+,&country=US&before=filing:20201231&after=filing:20150101&language=ENGLISH&type=PATENT'"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#搜尋patent csv\n",
    "keyword = ''\n",
    "assignee = ['Apple Inc.','Google LLC.'] #ex.['Apple Inc.','Google LLC.']\n",
    "s_date = '20150101'\n",
    "e_date = '20201231'\n",
    "search_google_patent(keyword, assignee, s_date, e_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 10/10 [05:29<00:00, 32.96s/it]\n"
     ]
    }
   ],
   "source": [
    "#爬蟲並新增資料\n",
    "data = pd.read_csv('US.csv', encoding= 'unicode_escape')\n",
    "urls = list(data.iloc[:, 0])\n",
    "del urls[0]\n",
    "\n",
    "for i in tqdm(range(0,10)):\n",
    "    data = soup(urls[i])\n",
    "    insert_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 15/333209 [00:07<44:22:02,  2.09it/s]"
     ]
    }
   ],
   "source": [
    "#資料庫查patent_url抓資料\n",
    "n_num = 1\n",
    "for i in range(10, 21):\n",
    "    patent = SearchYear(str(i))\n",
    "    print(str(n_num) + \"/\" + '11')\n",
    "    for j in tqdm(patent):\n",
    "        patent_num = j['url'].replace('https://patents.google.com/patent/', '')\n",
    "        Is_patent_num = SearchPatentNumber(str(i), str(patent_num))\n",
    "        if Is_patent_num:\n",
    "            n_num += 1\n",
    "            continue\n",
    "        else:\n",
    "            data = soup(j['url'])\n",
    "            insert_data(str(i), data)\n",
    "    n_num += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
